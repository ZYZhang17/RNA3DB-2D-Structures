# -*- coding: utf-8 -*-
"""
RNA 3D 结构分析脚本 (RDL1.6.7-1.4)

目的:
    遍历指定目录下的所有 mmCIF (.cif) 文件，利用 rnapolis-py 库分析每个文件，
    重点关注 RNA 链，并生成包含权威序列、RNApolis 原始输出以及
    修正后序列/结构的 CSV 报告。
    **修正：基于最新的 RNApolis 映射逻辑进行序列/结构修正。**

输入:
    - 一个包含 mmCIF 文件的目录路径。
    - rna3db 代码库路径 (通过 sys.path 添加)。
    - modifications_cache.json 文件路径。

输出:
    - 一个 CSV 文件，包含以下列:
        - PDB_ID
        - Chain_ID (权威链 ID, e.g., pdb_strand_id)
        - Sequence_Canonical (权威序列, 仅含 ACGUN)
        - Sequence_RNApolis_Raw (RNApolis 原始序列, find_gaps=False)
        - Structure_RNApolis_Raw (RNApolis 原始点括号结构)
        - Sequence_Corrected (修正后序列, 与权威等长, 含 -/ACGUN)
        - Structure_Corrected (修正后结构, 与权威等长, 含 .)
        - Resolution (分辨率)
        - Pairing_Type (分子内/分子间/无)
        - Pairing_Partners (配对链 ID 列表)
    - 一个日志文件。

依赖:
    - rnapolis-py
    - mmcif
    - tqdm
    - pandas
    - rna3db (需要能访问其代码)

使用方法:
    1. 确保已安装依赖 (`pip install rnapolis-py mmcif tqdm pandas`)。
    2. **重要:** 修改脚本开头的 `RNA3DB_SRC_DIR` 和 `MODIFICATIONS_CACHE_PATH` 为你的实际路径。
    3. 修改脚本末尾 `if __name__ == "__main__":` 部分的 `input_directory`,
       `output_csv_file` 和 `log_file` 变量为实际路径。
    4. 运行脚本: `python RDL1.6.7-1.4_mmcif_chain_analysis.py`
"""

import csv
import logging
import os
import sys
import time
from collections import defaultdict
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import Dict, List, Set, Tuple, Optional, Any
from functools import partial

# ----------------------------------------------------

# 导入 rnapolis 组件
from rnapolis.parser import read_3d_structure
from rnapolis.annotator import extract_secondary_structure
from rnapolis.common import Structure2D, Molecule, ResidueAuth, ResidueLabel, BasePair, BpSeq # 确保 BpSeq 已导入
from rnapolis.tertiary import Residue3D, Mapping2D3D, Structure3D
from rnapolis.util import handle_input_file

# 导入 mmcif 解析库
from mmcif.io.IoAdapterPy import IoAdapterPy
from tqdm import tqdm
import pandas as pd

# --- 尝试导入 ModificationHandler ---

parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)
    
try:
    from utils.modification_utils import ModificationHandler
    print("成功导入 ModificationHandler")
    USING_REAL_MODIFICATION_HANDLER = True
except ImportError as e:
    print(f"错误：无法导入ModificationHandler: {e}")
# ------------------------------------

# --- 配置：modifications_cache.json 路径 ---
MODIFICATIONS_CACHE_PATH = "./utils/modifications_cache.json"
# -----------------------------------------

# --- 配置日志记录 ---
def setup_logging(log_level_str: str, log_filepath: str):
    log_level = getattr(logging, log_level_str.upper(), logging.INFO)
    log_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    root_logger = logging.getLogger()
    root_logger.setLevel(log_level) # 设置根日志级别
    if root_logger.hasHandlers(): root_logger.handlers.clear()
    try:
        file_handler = logging.FileHandler(log_filepath, mode='w', encoding='utf-8')
        file_handler.setFormatter(log_formatter)
        file_handler.setLevel(log_level) # 文件handler也遵循根级别
        root_logger.addHandler(file_handler)
    except Exception as e: print(f"错误：无法设置日志文件 handler 到 {log_filepath}: {e}")
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(log_formatter)
    console_handler.setLevel(log_level) # 控制台handler也遵循根级别
    root_logger.addHandler(console_handler)

logger = logging.getLogger(__name__) # 获取当前模块的logger

# --- 辅助函数：解析权威序列 (使用 ModificationHandler) ---
def _parse_pdbx_poly_seq_scheme_detailed(
    cif_file_path: str,
    modification_handler: ModificationHandler
) -> Optional[Dict[str, List[Dict]]]:
    scheme_data_by_chain = defaultdict(list)
    try:
        io_adapter = IoAdapterPy()
        data_containers = io_adapter.readFile(cif_file_path)
        if not data_containers:
            logger.error(f"文件 {os.path.basename(cif_file_path)}: 无法读取 mmCIF 数据容器。")
            return None
        data_block = data_containers[0]
        scheme_obj = data_block.getObj("pdbx_poly_seq_scheme")
        if not scheme_obj:
            logger.info(f"文件 {os.path.basename(cif_file_path)}: 未找到 'pdbx_poly_seq_scheme' 对象。")
            return {}

        attributes = scheme_obj.getAttributeList()
        required_attrs_base = ["pdb_strand_id", "seq_id", "mon_id"]
        auth_seq_num_attr = None
        if "pdb_seq_num" in attributes: auth_seq_num_attr = "pdb_seq_num"
        elif "auth_seq_num" in attributes: auth_seq_num_attr = "auth_seq_num"
        else:
            logger.error(f"文件 {os.path.basename(cif_file_path)}: 解析 _pdbx_poly_seq_scheme 时缺少作者序列号属性。")
            return None

        required_attrs = required_attrs_base + [auth_seq_num_attr]
        if not all(attr in attributes for attr in required_attrs):
            missing = [attr for attr in required_attrs if attr not in attributes]
            logger.error(f"文件 {os.path.basename(cif_file_path)}: 解析 _pdbx_poly_seq_scheme 时缺少必要属性: {missing}.")
            return None

        chain_idx = attributes.index("pdb_strand_id")
        seq_id_idx = attributes.index("seq_id")
        mon_id_idx = attributes.index("mon_id")
        auth_seq_num_idx = attributes.index(auth_seq_num_attr)
        ins_code_idx = attributes.index("pdb_ins_code") if "pdb_ins_code" in attributes else -1

        for row in scheme_obj.getRowList():
            try:
                chain_id = row[chain_idx]
                seq_id_val = row[seq_id_idx]
                seq_id = int(seq_id_val) if seq_id_val not in ['.', '?'] else -1
                mon_id = row[mon_id_idx]
                auth_seq_num_val = row[auth_seq_num_idx]
                auth_seq_num = int(auth_seq_num_val) if auth_seq_num_val not in ['.', '?'] else -1
                ins_code_raw = row[ins_code_idx] if ins_code_idx != -1 else '?'
                ins_code = ins_code_raw if ins_code_raw not in ['?', '.'] else None
                std_one_letter_code = modification_handler.rna_letters_3to1(mon_id)
                scheme_data_by_chain[chain_id].append({
                    "seq_id": seq_id, "mon_id": mon_id, "std_one_letter_code": std_one_letter_code,
                    "auth_seq_num": auth_seq_num, "pdb_ins_code": ins_code
                })
            except (ValueError, IndexError) as e:
                logger.warning(f"文件 {os.path.basename(cif_file_path)}: 解析 _pdbx_poly_seq_scheme 行时出错: {row} - {e}")
                continue

        for chain_id_key in scheme_data_by_chain:
            scheme_data_by_chain[chain_id_key].sort(key=lambda x: x["seq_id"])
        return dict(scheme_data_by_chain)

    except FileNotFoundError:
        logger.error(f"文件 {os.path.basename(cif_file_path)}: 尝试解析权威序列时文件未找到。")
        return None
    except Exception as e:
        logger.error(f"文件 {os.path.basename(cif_file_path)}: 解析 _pdbx_poly_seq_scheme 时发生意外错误: {e}", exc_info=False)
        return None

# --- 辅助函数：解析多行点括号 ---
def parse_multiline_dot_bracket(dot_bracket_multiline: str, pdb_id: str) -> Dict[str, Tuple[str, str]]:
    parsed_data = {}
    if not dot_bracket_multiline or not dot_bracket_multiline.strip():
        logger.warning(f"文件 {pdb_id}: 传入的点括号字符串为空。")
        return parsed_data

    strands_data = dot_bracket_multiline.strip().split('\n>')
    if strands_data and strands_data[0].startswith('>'):
        strands_data[0] = strands_data[0][1:]

    for i, strand_block in enumerate(strands_data):
        if not strand_block.strip(): continue
        lines = strand_block.strip().split('\n')
        if len(lines) == 3:
            strand_id_raw = lines[0].strip()
            sequence = lines[1].strip()
            structure = lines[2].strip()
            strand_id_key = strand_id_raw[len("strand_"):] if strand_id_raw.lower().startswith("strand_") else strand_id_raw
            if strand_id_key in parsed_data:
                old_seq_len = len(parsed_data[strand_id_key][0])
                new_seq_len = len(sequence)
                if new_seq_len > old_seq_len:
                    logger.info(f"文件 {pdb_id}: 重复链ID '{strand_id_key}'，新数据更长，已覆盖。")
                    parsed_data[strand_id_key] = (sequence, structure)
                else:
                    logger.info(f"文件 {pdb_id}: 重复链ID '{strand_id_key}'，新数据不长于旧数据，保留旧数据。")
            else:
                parsed_data[strand_id_key] = (sequence, structure)
        elif len(lines) == 1 and not lines[0]: continue
        else: logger.warning(f"文件 {pdb_id}: 解析点括号块时遇到意外格式: {lines}")
    return parsed_data

# --- 解析分辨率辅助函数 ---
def _parse_resolution(cif_file_path: str) -> str:
    try:
        io_adapter = IoAdapterPy()
        data_containers = io_adapter.readFile(cif_file_path)
        if not data_containers: return "N/A"
        data_block = data_containers[0]
        refine_obj = data_block.getObj("refine")
        if not refine_obj: return "N/A"
        attributes = refine_obj.getAttributeList(); res_attr = "ls_d_res_high"
        if res_attr not in attributes: return "N/A"
        res_idx = attributes.index(res_attr); rows = refine_obj.getRowList()
        if not rows: return "N/A"
        resolution_val = rows[0][res_idx]
        return resolution_val if resolution_val not in ['?', '.'] else "N/A"
    except Exception: # 保持简洁，不打印每个文件的分辨率解析错误
        return "N/A"

# --- 工作函数：处理单个文件 ---
def process_file(
    cif_path: str,
    modification_handler: ModificationHandler
) -> List[List[str]]:
    file_rows = []
    pdb_id = os.path.splitext(os.path.basename(cif_path))[0]
    logger.info(f"开始处理文件: {pdb_id}")
    temp_cif_handle = None
    rna_chain_auth_ids = set()
    existing_3d_residues_by_auth_id: Dict[Tuple, Residue3D] = {}
    canonical_residues_by_pdb_strand_id: Optional[Dict[str, List[Dict]]] = None
    structure3d: Optional[Structure3D] = None
    structure2d_obj: Optional[Structure2D] = None # 重命名以区分
    mapping: Optional[Mapping2D3D] = None
    rnapolis_parsed_data = {}
    residue_to_rnapolis_idx = {}
    rnapolis_idx_to_chars = {}
    pairing_partners = defaultdict(set)
    rna_structure_type = {} # 使用 auth_chain_id 作为键
    resolution = "N/A"

    try:
        temp_cif_handle = handle_input_file(cif_path)
        temp_cif_path = temp_cif_handle.name

        canonical_residues_by_pdb_strand_id = _parse_pdbx_poly_seq_scheme_detailed(
            temp_cif_path, modification_handler
        )
        if canonical_residues_by_pdb_strand_id is None:
            logger.error(f"文件 {pdb_id}: 无法解析权威序列信息，跳过。")
            return file_rows

        resolution = _parse_resolution(temp_cif_path)

        temp_cif_handle.seek(0)
        structure3d = read_3d_structure(temp_cif_handle, model=None, nucleic_acid_only=False)
        if not structure3d or not structure3d.residues:
            logger.warning(f"文件 {pdb_id}: RNApolis 未找到3D残基。")
            return file_rows

        chain_molecule_types: Dict[str, set] = defaultdict(set)
        for residue in structure3d.residues:
            auth_chain_id = residue.auth.chain if residue.auth else None
            if auth_chain_id:
                chain_molecule_types[auth_chain_id].add(residue.molecule_type)
                if residue.auth:
                    auth_id = (residue.auth.chain, residue.auth.number, residue.auth.icode)
                    existing_3d_residues_by_auth_id[auth_id] = residue
        for chain_id, types in chain_molecule_types.items():
            if Molecule.RNA in types: rna_chain_auth_ids.add(chain_id)

        if not rna_chain_auth_ids:
            logger.info(f"文件 {pdb_id}: 未找到 RNA 链。")
            return file_rows

        try:
            result_tuple = extract_secondary_structure(structure3d, model=None, find_gaps=False, all_dot_brackets=False)
            if result_tuple and isinstance(result_tuple[0], Structure2D):
                structure2d_obj = result_tuple[0]
                base_pairs = structure2d_obj.baseInteractions.basePairs if structure2d_obj.baseInteractions else []
                stackings = structure2d_obj.baseInteractions.stackings if structure2d_obj.baseInteractions else []
                mapping = Mapping2D3D(structure3d, base_pairs, stackings, False)
                rnapolis_parsed_data = parse_multiline_dot_bracket(structure2d_obj.dotBracket, pdb_id)

                if mapping:
                    if hasattr(mapping, 'bpseq_index_to_residue_map') and mapping.bpseq_index_to_residue_map:
                        temp_map = mapping.bpseq_index_to_residue_map
                        residue_to_rnapolis_idx = {v: k for k, v in temp_map.items()}
                    else: logger.warning(f"文件 {pdb_id}: mapping.bpseq_index_to_residue_map 不可用。")

                    if hasattr(mapping, 'bpseq') and isinstance(mapping.bpseq, BpSeq) and \
                       hasattr(mapping.bpseq, 'dot_bracket') and mapping.bpseq.dot_bracket and \
                       hasattr(mapping.bpseq.dot_bracket, 'sequence') and \
                       hasattr(mapping.bpseq.dot_bracket, 'structure'):
                        internal_seq = mapping.bpseq.dot_bracket.sequence
                        internal_struct = mapping.bpseq.dot_bracket.structure
                        if len(internal_seq) == len(internal_struct):
                            for i in range(len(internal_seq)): rnapolis_idx_to_chars[i + 1] = (internal_seq[i], internal_struct[i])
                        else: logger.error(f"文件 {pdb_id}: mapping.bpseq.dot_bracket 序列/结构长度不匹配。")
                    else:
                        logger.warning(f"文件 {pdb_id}: mapping.bpseq.dot_bracket 不可用，回退构建 rnapolis_idx_to_chars。")
                        current_idx = 1
                        sorted_strand_keys = sorted(rnapolis_parsed_data.keys())
                        temp_s, temp_db = "", ""
                        for key in sorted_strand_keys: seq, struct = rnapolis_parsed_data[key]; temp_s += seq; temp_db += struct
                        if len(temp_s) == len(temp_db):
                            for i in range(len(temp_s)): rnapolis_idx_to_chars[current_idx] = (temp_s[i], temp_db[i]); current_idx += 1
                        else: logger.error(f"文件 {pdb_id}: 回退构建 rnapolis_idx_to_chars 时长度不匹配。")
                else: logger.warning(f"文件 {pdb_id}: Mapping2D3D 对象未创建。")
            else: logger.warning(f"文件 {pdb_id}: RNApolis 未能提取二级结构。")
        except Exception as e_rnapolis: logger.error(f"文件 {pdb_id}: RNApolis 分析时出错: {e_rnapolis}", exc_info=False)

        if structure2d_obj:
            rna_chain_has_pairs = defaultdict(bool)
            base_pairs_from_rnapolis: List[BasePair] = structure2d_obj.baseInteractions.basePairs
            for bp in base_pairs_from_rnapolis:
                res1_3d = structure3d.find_residue(bp.nt1.label, bp.nt1.auth)
                res2_3d = structure3d.find_residue(bp.nt2.label, bp.nt2.auth)
                if res1_3d and res1_3d.auth and res2_3d and res2_3d.auth:
                    nt1_auth_chain, nt2_auth_chain = res1_3d.auth.chain, res2_3d.auth.chain
                    if nt1_auth_chain and nt2_auth_chain:
                        pairing_partners[nt1_auth_chain].add(nt2_auth_chain)
                        pairing_partners[nt2_auth_chain].add(nt1_auth_chain)
                        if nt1_auth_chain in rna_chain_auth_ids:
                            rna_chain_has_pairs[nt1_auth_chain] = True
                            if nt1_auth_chain != nt2_auth_chain: rna_structure_type[nt1_auth_chain] = "intermolecular"
                        if nt2_auth_chain in rna_chain_auth_ids:
                            rna_chain_has_pairs[nt2_auth_chain] = True
                            if nt1_auth_chain != nt2_auth_chain and rna_structure_type.get(nt2_auth_chain) != "intermolecular":
                                rna_structure_type[nt2_auth_chain] = "intermolecular"
            for rna_auth_chain_id in rna_chain_auth_ids:
                 if rna_auth_chain_id not in rna_structure_type:
                     rna_structure_type[rna_auth_chain_id] = "intramolecular" if rna_chain_has_pairs[rna_auth_chain_id] else "no_secondary_structure_found"
        else:
             for rna_auth_chain_id in rna_chain_auth_ids: rna_structure_type[rna_auth_chain_id] = "N/A (RNApolis failed)"

        for pdb_strand_id, canonical_residue_list in canonical_residues_by_pdb_strand_id.items():
            representative_auth_chain_id = None
            if canonical_residue_list:
                 first_canon_res = canonical_residue_list[0]
                 for auth_id_3d, res3d_obj in existing_3d_residues_by_auth_id.items():
                     if res3d_obj.auth and res3d_obj.auth.number == first_canon_res['auth_seq_num'] and \
                        res3d_obj.auth.icode == first_canon_res['pdb_ins_code'] and \
                        res3d_obj.auth.chain == pdb_strand_id:
                          representative_auth_chain_id = res3d_obj.auth.chain; break
                 if not representative_auth_chain_id and pdb_strand_id in chain_molecule_types:
                     representative_auth_chain_id = pdb_strand_id
            if not representative_auth_chain_id or representative_auth_chain_id not in rna_chain_auth_ids:
                continue

            canonical_sequence = "".join([res['std_one_letter_code'] for res in canonical_residue_list])
            corrected_sequence_chars, corrected_structure_chars = [], []
            rnapolis_raw_seq, rnapolis_raw_struct = "N/A", "N/A"
            
            # rnapolis_parsed_data 的键是 RNApolis 输出的 strand_X 中的 X (例如 C, D)
            # representative_auth_chain_id 是 PDB 的链ID (例如 C, D)
            # 假设 X 与 PDB 链ID 一致
            target_key_for_raw = representative_auth_chain_id
            if target_key_for_raw in rnapolis_parsed_data:
                rnapolis_raw_seq, rnapolis_raw_struct = rnapolis_parsed_data[target_key_for_raw]
            else: # 尝试大小写不敏感或原始 pdb_strand_id
                found_raw = False
                for rnap_key_iter in rnapolis_parsed_data.keys():
                    if rnap_key_iter.upper() == target_key_for_raw.upper():
                        rnapolis_raw_seq, rnapolis_raw_struct = rnapolis_parsed_data[rnap_key_iter]
                        found_raw = True; break
                if not found_raw and pdb_strand_id in rnapolis_parsed_data: # 备用：使用原始pdb_strand_id作为key
                     rnapolis_raw_seq, rnapolis_raw_struct = rnapolis_parsed_data[pdb_strand_id]


            for canon_res in canonical_residue_list:
                auth_id_to_lookup = (representative_auth_chain_id, canon_res['auth_seq_num'], canon_res['pdb_ins_code'])
                res3d = existing_3d_residues_by_auth_id.get(auth_id_to_lookup)
                if res3d is None:
                    corrected_sequence_chars.append('-'); corrected_structure_chars.append('.')
                else:
                    rnapolis_idx = residue_to_rnapolis_idx.get(res3d)
                    if rnapolis_idx is None:
                        corrected_sequence_chars.append(canon_res['std_one_letter_code']); corrected_structure_chars.append('.')
                    else:
                        _, struct_char = rnapolis_idx_to_chars.get(rnapolis_idx, ('?', '.'))
                        corrected_sequence_chars.append(canon_res['std_one_letter_code']); corrected_structure_chars.append(struct_char)
            
            corrected_sequence = "".join(corrected_sequence_chars)
            corrected_structure = "".join(corrected_structure_chars)
            structure_type_str = rna_structure_type.get(representative_auth_chain_id, "N/A")
            partners = pairing_partners.get(representative_auth_chain_id, set())
            other_partners = partners - {representative_auth_chain_id}
            partners_str = ", ".join(sorted(list(other_partners))) if other_partners else ("无" if structure_type_str == "intramolecular" else "N/A")
            if structure_type_str == "no_secondary_structure_found": partners_str = "无"


            file_rows.append([
                pdb_id, pdb_strand_id, canonical_sequence or "N/A",
                rnapolis_raw_seq, rnapolis_raw_struct,
                corrected_sequence or "N/A", corrected_structure or "N/A",
                resolution, structure_type_str, partners_str
            ])
        logger.info(f"完成文件: {pdb_id}")

    except Exception as e:
        logger.error(f"处理文件 {pdb_id} 时发生主错误: {e}", exc_info=False) # 保持简洁
        return []
    finally:
        if temp_cif_handle and hasattr(temp_cif_handle, 'close') and not temp_cif_handle.closed:
             try: temp_cif_handle.close()
             except Exception as e_close: logger.warning(f"无法关闭临时文件句柄 for {pdb_id}: {e_close}")
    return file_rows

# --- 主程序 ---
def run_batch_analysis(input_dir: str, output_csv: str, log_filepath: str, max_workers: int = None):
    log_level_str = os.getenv("LOGLEVEL", "INFO") # 默认 INFO
    setup_logging(log_level_str, log_filepath)
    logging.getLogger("rnapolis").setLevel(logging.WARNING) # rnapolis 内部日志设为 WARNING

    modification_handler = None
    if not os.path.exists(MODIFICATIONS_CACHE_PATH):
        logger.error(f"错误：modifications_cache.json 文件未找到于: {MODIFICATIONS_CACHE_PATH}")
        modification_handler = ModificationHandler()
    else:
        if USING_REAL_MODIFICATION_HANDLER:
            try:
                modification_handler = ModificationHandler(MODIFICATIONS_CACHE_PATH)
                logger.info(f"成功加载 ModificationHandler 从: {MODIFICATIONS_CACHE_PATH}")
            except Exception as e:
                logger.error(f"加载 ModificationHandler 时出错: {e}", exc_info=True)
                modification_handler = ModificationHandler()
        else:
            modification_handler = ModificationHandler()

    start_time = time.time()
    logger.info(f"脚本启动: RNA 结构分析 (RDL1.6.7-1.4)")
    logger.info(f"输入目录: {input_dir}")
    logger.info(f"输出 CSV: {output_csv}")
    logger.info(f"日志文件: {log_filepath}")

    try:
        all_files = [f for f in os.listdir(input_dir) if f.lower().endswith((".cif", ".cif.gz"))]
        cif_files = [os.path.join(input_dir, f) for f in all_files]
        if not cif_files: logger.warning(f"目录 {input_dir} 中未找到 .cif 或 .cif.gz 文件。"); return
        logger.info(f"找到 {len(cif_files)} 个文件待处理。")
    except FileNotFoundError: logger.error(f"输入目录不存在: {input_dir}"); return
    except Exception as e: logger.error(f"读取输入目录时出错: {e}"); return

    try:
        with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow([
                'PDB_ID', 'Chain_ID', 'Sequence_Canonical',
                'Sequence_RNApolis_Raw', 'Structure_RNApolis_Raw',
                'Sequence_Corrected', 'Structure_Corrected',
                'Resolution', 'Pairing_Type', 'Pairing_Partners'
            ])

            num_workers = max_workers if max_workers else os.cpu_count()
            logger.info(f"使用 {num_workers} 个进程进行并行处理...")

            processed_files_count = 0
            error_files_count = 0 # 用于记录子进程中真正出错的文件

            with ProcessPoolExecutor(max_workers=num_workers) as executor:
                process_file_with_handler = partial(process_file, modification_handler=modification_handler)
                futures = {executor.submit(process_file_with_handler, cif_path): cif_path for cif_path in cif_files}

                for future in tqdm(as_completed(futures), total=len(cif_files), desc="处理 CIF 文件"):
                    cif_path = futures[future]
                    pdb_id_for_log = os.path.splitext(os.path.basename(cif_path))[0]
                    try:
                        file_result_rows = future.result() # result() 会重新抛出子进程中的异常
                        if file_result_rows: # 如果返回非空列表，说明有数据写入
                            writer.writerows(file_result_rows)
                            processed_files_count +=1
                        # else: process_file 内部已经记录了跳过的原因 (如无RNA链)
                    except Exception as exc: # 捕获子进程中未处理的异常
                        logger.error(f"文件 {pdb_id_for_log} 在子进程中处理失败: {exc}", exc_info=False) # 保持简洁
                        error_files_count += 1
            
            skipped_files_count = len(cif_files) - processed_files_count - error_files_count

    except IOError as e: logger.error(f"无法写入 CSV 文件 {output_csv}: {e}"); return
    except Exception as e: logger.error(f"主程序发生未知错误: {e}", exc_info=True); return

    end_time = time.time()
    duration = end_time - start_time
    logger.info("-" * 50)
    logger.info(f"分析完成!")
    logger.info(f"总共检查文件数: {len(cif_files)}")
    logger.info(f"成功处理并写入数据的文件数: {processed_files_count}")
    logger.info(f"处理失败的文件数 (子进程错误): {error_files_count}")
    logger.info(f"跳过的文件数 (无RNA链或RNApolis无结果等): {skipped_files_count}")
    # logger.info(f"写入 CSV 的总 RNA 链数: {processed_chains_count}") # 这个计数在当前逻辑下不易准确，可移除或修改
    logger.info(f"总耗时: {duration:.2f} 秒")
    logger.info(f"结果已保存至 CSV: {output_csv}")
    logger.info(f"详细日志已保存至: {log_filepath}")
    logger.info("-" * 50)

# --- 主程序入口 ---
if __name__ == "__main__":
    input_directory = "./data/downloaded_mmcif"
    output_csv_file = "./data/analysis_output/02_rna_chain_analysis.csv"
    log_file = "./data/analysis_output/02_analyze_rna_chains.log"
    num_parallel_workers = 80
    run_batch_analysis(input_directory, output_csv_file, log_file, num_parallel_workers)